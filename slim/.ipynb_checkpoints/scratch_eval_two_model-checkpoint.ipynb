{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets import dataset_factory\n",
    "from deployment import model_deploy\n",
    "from nets import nets_factory\n",
    "from preprocessing import preprocessing_factory\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants\n",
    "class Flags:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "flags = Flags()\n",
    "flags.dataset_name= \"rcmp\" \n",
    "flags.dataset_split_name = 'validation'\n",
    "flags.dataset_dir = \"/home/renming.qi/flower_photos/\"\n",
    "flags.model_path = \"/home/renming.qi/models/pretrained/inception_resnet_v2.ckpt\"\n",
    "flags.batch_size = 5\n",
    "flags.filename = [\"/home/renming.qi/flower_photos/rcmp_train_00000-of-00002.tfrecord\",\n",
    "                  \"/home/renming.qi/flower_photos/rcmp_train_00001-of-00002.tfrecord\"]\n",
    "flags.checkpoint_exclude_scopes= 'InceptionResnetV2/Logits,InceptionResnetV2/AuxLogits'\n",
    "flags.model_name  =  \"inception_resnet_v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rcmp_decoder():\n",
    "    \"\"\"\n",
    "    TODO: Fix this\n",
    "    the tfexample encoding and decoing are wrong but will not affect the result.\n",
    "    \n",
    "    \"\"\"\n",
    "    keys_to_features = {\n",
    "      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "      'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),\n",
    "      'image/class/label': tf.FixedLenFeature(\n",
    "          [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "      'image/filename': tf.FixedLenFeature(\n",
    "          [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "    }\n",
    "\n",
    "    #Create the items_to_handlers dictionary for the decoder.\n",
    "    items_to_handlers = {\n",
    "    'image': slim.tfexample_decoder.Image(),\n",
    "    'label': slim.tfexample_decoder.Tensor('image/class/label'),\n",
    "    'name' : slim.tfexample_decoder.Tensor('image/filename')\n",
    "    }\n",
    "\n",
    "    #Start to create the decoder\n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "    return decoder \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset \n",
    "tf_dataset = tf.data.TFRecordDataset([\"/home/renming.qi/flower_photos/rcmp_train_00000-of-00002.tfrecord\",\"/home/renming.qi/flower_photos/rcmp_train_00001-of-00002.tfrecord\"])\n",
    "decoder = get_rcmp_decoder()\n",
    "#dataset transformation \n",
    "dataset = tf_dataset.map(lambda x : decoder.decode(x)).map(lambda x,y,z: (tf.image.resize_images(x,[299,299]),y,z))\n",
    "batched_dataset = dataset.batch(flags.batch_size)\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "batched_images, batched_labels, _ =  next_element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset transformation \n",
    "# with tf.Session() as sess:\n",
    "#     while True:\n",
    "#         try:\n",
    "#             print(sess.run(batched_labels))\n",
    "#         except tf.errors.OutOfRangeError:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusions = [scope.strip() for scope in flags.checkpoint_exclude_scopes.split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_fn = nets_factory.get_network_fn(\n",
    "        flags.model_name,\n",
    "        num_classes= 2 ,\n",
    "        is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_scope_first = \"m1\"\n",
    "root_scope_second= \"m2\"\n",
    "with tf.variable_scope(root_scope_first):\n",
    "    logits_first, end_points_first = network_fn(batched_images)\n",
    "with tf.variable_scope(root_scope_second):\n",
    "    logits_second, end_points_second = network_fn(batched_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(slim.get_model_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     iterator = tfdataset.make_one_shot_iterator()\n",
    "#     next_element = iterator.get_next()\n",
    "#     for i in range(1):\n",
    "#         val =  sess.run(next_element)\n",
    "#         print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_to_restore(extra_root_scope,):\n",
    "    variables_to_restore = []\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(extra_root_scope + \"/\" + exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if (not excluded) and var.op.name.startswith(extra_root_scope):\n",
    "            variables_to_restore.append(var)\n",
    "    return variables_to_restore\n",
    "def name_in_checkpoint(var,extra_root_scope):\n",
    "    if extra_root_scope in var.op.name:\n",
    "#         print(extra_root_scope)\n",
    "#         print(var.op.name)\n",
    "#         print(\"+\" + var.op.name)\n",
    "\n",
    "        return var.op.name.replace(extra_root_scope,\"\",1).strip(\"/\")\n",
    "    else:\n",
    "        print(extra_root_scope)\n",
    "        print(var.op.name)\n",
    "        print(\"-\" + var.op.name)\n",
    "        return var.op.name\n",
    "    \n",
    "def merge_dicts(*dict_args):\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_restore_first = get_variables_to_restore(root_scope_first)\n",
    "variables_to_restore_second = get_variables_to_restore(root_scope_second)\n",
    "\n",
    "map_variables_to_restore_first = {name_in_checkpoint(var,root_scope_first): var for var in variables_to_restore_first}\n",
    "map_variables_to_restore_second = {name_in_checkpoint(var,root_scope_second): var for var in variables_to_restore_second}\n",
    "\n",
    "# variables_to_restore = variables_to_restore_first\n",
    "# variables_to_restore.extend(variables_to_restore_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    restorer_first = tf.train.Saver(map_variables_to_restore_first)\n",
    "    restorer_first.restore(sess,flags.model_path)\n",
    "    restorer_second = tf.train.Saver(map_variables_to_restore_second)\n",
    "    restorer_second.restore(sess,flags.model_path)\n",
    "    tf.global_variables_initializer().run()\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(next_element)\n",
    "            p1,p2 = sess.run([ end_points_first['Predictions'],end_points_second['Predictions']])\n",
    "            print(p1)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p2[0:1,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = tf.data.Iterator.from_structure(output_types=tf.int32)\n",
    "# sess = tf.InteractiveSession()\n",
    "# inc_dataset = tf.data.Dataset.range(100)\n",
    "# dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "# dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "# batched_dataset = dataset.batch(4)\n",
    "\n",
    "# iterator = batched_dataset.make_one_shot_iterator()\n",
    "# next_element = iterator.get_next()\n",
    "\n",
    "# print(sess.run(next_element))  # ==> ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])\n",
    "# print(sess.run(next_element))  # ==> ([4, 5, 6,   7],   [-4, -5,  -6,  -7])\n",
    "# print(sess.run(next_element))  # ==> ([8, 9, 10, 11],   [-8, -9, -10, -11])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
